{
    "params":
    {
        "r": 16,
        "lora_alpha": 32,
        "lora_dropout": 0.1,

        "lr_scheduler_type" : "cosine",
        "max_seq_length" : 512,
        "output_dir" : "outputs-t3q",
        "train_batch_size" : 1,
        "eval_batch_size" : 1,
        "epoch" : 3,
        "learning_rate" : "2e-5",
        "weight_decay" : 0.01,

        "gradient_accumulation_steps" : 4,
        "fp16" : false,
        "fp16_full_eval" : false,
        "warmup_ratio" : 0.0,

        "logging_steps" : 100,
        "save_strategy" : "epoch",

        "do_eval" : true,
        "eval_strategy" : "epoch",
        "eval_steps" : null,
        "load_best_model_at_end" : false,
        "metric_for_best_model" : "eval_loss",
        "greater_is_better" : false
    },

    "model" : 
    {
        "name" : "T3Q-LLM/T3Q-LLM1-sft1.0-dpo1.0"
    },

    "data" :
    {
        "data_path" : "../data",
        "train_file" : "train-splited.csv",
        "dev_file" : "dev-splited.csv",
        "test_file" : "test.csv",
        "filtering_input_ids_length": 1024,
        "tokenizer_num_procs": 1,
        "use_4-choices_prompt": true,
        "test_size": 0.2
    },

    "experiment" :
    {
        "output_dir" : "experiments",
        "last_eval_strategy" : "no",
        "save_train_dataset" : true,
        "save_eval_dataset" : true
    }
}